## 理解
神经网络可以看作是一个万能函数近似器。
而由神经网络构成的深度学习模型，可以看成一个函数空间黑盒子，里边封装了无数的映射函数，从输入空间到输出空间的映射函数，像一个封闭的房间从一面墙到对面的另一面墙上连了无数的线，线就是映射函数，你不用管中间的线是怎么走的，你只需要知道，你只要从墙这边给它一个确定的输入，它肯定可以根据两个墙之间的线在对面墙得到一个唯一的输出。表面上看，通过训练得到了无数的超参数，实际上这些超参数就是函数的具象表现。
映射函数可以是任意两个空间的映射函数，比如：中英翻译就是中文的空间到英文空间的映射，图片数据空间到文字空间，音频数据空间到文字空间...等

## NLP 特征提取器
CNN（速度快、可并行、适合用于分类；局限性：没法解决上下文。扩展：中心缩放的卷积核）
RNN（可以一定程度改善长距离依赖、LSTM 改善了容易出现的梯度爆炸和梯度消失，因为存在各种门，序列模型，不可并行。信息保留的多少取决于距离，有说 200 字，所以一般双向。）
Transformer（特征提取器，可并行，又可解决长距离依赖，当前效果最好，与 RNN 相比，基于自注意力机制，与距离无关）
