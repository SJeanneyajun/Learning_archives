# 包括
自然语言处理 NLP 包括 自然语言理解和自然语言生成。
# 关键词
语料(corpus)库、词向量、分词、词频、构建树、HMM
词性分析、语义消歧、停用词
# 熵（信息复杂度）
为什么要用 log 表示复杂度。信息熵，香农提出来。一个信息最少可以用几位 bit 表示出来。位数即是：幂数
# 数据结构 
图
拓扑图
有向无环图
有向有权图
无向有权图
##分词相关
 jieba 原理
[中文分词的基本原理以及jieba分词的用法](https://blog.csdn.net/John_xyz/article/details/54645527)
### 动态规划
### HMM（隐马尔可夫模型）
[一文搞懂HMM（隐马尔可夫模型）](http://www.cnblogs.com/skyme/p/4651331.html)
[隐马尔科夫模型（HMM)及其扩展](https://blog.csdn.net/stdcoutzyx/article/details/8522078)
### Viterbi（维特比算法）
[wiki 维特比算法](https://zh.wikipedia.org/wiki/%E7%BB%B4%E7%89%B9%E6%AF%94%E7%AE%97%E6%B3%95)
### 新词发现（字的互信息和左右熵信息）凝固度、自由度
[互联网时代的社会语言学：基于SNS的文本数据挖掘](http://www.matrix67.com/blog/archives/5044)
## TF-IDF（TF：Term Frequency/词频，IDF：Inverse Document Frequency/逆文档频率）
TF：词频，实际是词频的归一化。归一化是要排除掉文章长短对词频的影响。
IDF：逆文档频率，一个权重，用来表示该词的常见不常见，对文章的分类能力强不强。该词在文档中出现次数越多，权重越小，所以叫逆文档频率。
TF-IDF 值 指  TF * IDF，某词对文章的重要性越高，它的 TF-IDF 指越高。

[阮一峰 TF-IDF与余弦相似性的应用（一）：自动提取关键词](http://www.ruanyifeng.com/blog/2013/03/tf-idf.html)
[TF-IDF与余弦相似性的应用（二）：找出相似文章](http://www.ruanyifeng.com/blog/2013/03/cosine_similarity.html)
[TF-IDF与余弦相似性的应用（三）：自动摘要](http://www.ruanyifeng.com/blog/2013/03/automatic_summarization.html)
[百度百科 TF-IDF](https://baike.baidu.com/item/tf-idf)
[wiki - TF-IDF](https://zh.wikipedia.org/wiki/Tf-idf)

## TextRank
[分词TextRank算法解读](https://blog.csdn.net/Changer_sun/article/details/79234065)
[textrank算法原理与提取关键词、自动提取摘要PYTHON](https://blog.csdn.net/HHTNAN/article/details/78032712)

## HMM 隐马尔科夫
## CRF 条件随机场
## BiLSTM 双向 LSTM







